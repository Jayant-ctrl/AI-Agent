# ğŸš€ AI Agent Project

This project is an AI-powered chatbot agent that allows users to interact with different large language models (LLMs) such as LLaMA 3, DeepSeek, Mixtral, and Whisper. It uses FastAPI for the backend and Streamlit for the frontend.

---

## ğŸ“Œ Features

- Select from multiple LLM models (LLaMA 3, DeepSeek, Mixtral, Whisper)
- Define a custom system prompt for the agent
- Choose between Groq or Gemini API providers
- Optional web search functionality powered by Tavily
- Interactive UI built with Streamlit
- FastAPI-powered backend for seamless interaction

---

## ğŸ›  Tech Stack

### **Frontend:**
- Streamlit (UI)

### **Backend:**
- FastAPI (API Framework)
- Uvicorn (ASGI Server)
- Pydantic (Schema Validation)
- LangChain (LLM Integration)
- LangGraph (Agentic Framework)
- Tavily (Web Search API)

---

## âš™ï¸ Installation & Setup

### **1ï¸âƒ£ Clone the Repository**
```sh
 git clone https://github.com/your-username/ai-agent.git
 cd ai-agent
```

### **2ï¸âƒ£ Set Up Virtual Environment (Recommended)**
```sh
 python -m venv venv
 source venv/bin/activate  # macOS/Linux
 venv\Scripts\activate     # Windows
```

### **3ï¸âƒ£ Install Dependencies**
```sh
 pip install -r requirements.txt
```

### **4ï¸âƒ£ Set Up Environment Variables**
Create a `.env` file in the `backend/` folder and add:
```env
GROQ_API_KEY=your_groq_api_key
TAVILY_API_KEY=your_tavily_api_key
GEM_API_KEY=your_gemini_api_key
```

You can find an example `.env.example` file in the repository.

---

## ğŸš€ Running the Project

### **Run Backend (FastAPI)**
```sh
 cd backend
 uvicorn backend:app --host 127.0.0.1 --port 9999
```
The FastAPI docs can be accessed at: [http://127.0.0.1:9999/docs](http://127.0.0.1:9999/docs)

### **Run Frontend (Streamlit UI)**
```sh
 cd frontend
 streamlit run frontend.py
```

Now, open [http://localhost:8501](http://localhost:8501) in your browser to access the UI.

---

## ğŸ“¡ API Endpoints

### **POST /chat**
- **Description:** Interacts with the AI agent and returns a response.
- **Request Body:**
```json
{
  "model_name": "llama3-70b-8192",
  "model_provider": "Groq",
  "system_prompt": "Act as a smart AI chatbot",
  "messages": ["Hello, what can you do?"],
  "allow_search": true
}
```
- **Response:**
```json
{
  "response": "Hello! I am your AI agent. How can I assist you today?"
}
```

---

## ğŸ“œ Folder Structure
```bash
ai-agent/
â”‚â”€â”€ backend/
â”‚   â”‚â”€â”€ ai_agent.py        # Core AI agent logic
â”‚   â”‚â”€â”€ backend.py         # FastAPI backend
â”‚â”€â”€ frontend/
â”‚   â”‚â”€â”€ frontend.py        # Streamlit UI
â”‚â”€â”€ .env.example           # Environment variable example
â”‚â”€â”€ requirements.txt       # Dependencies
â”‚â”€â”€ README.md              # Documentation
â”‚â”€â”€ .gitignore             # Ignored files
â”‚â”€â”€ LICENSE                # License
â”‚â”€â”€ run.sh                 # Script to start backend and frontend
```

---

## ğŸ¥ Demo Video
![Watch the demo](demo.mp4)

---

## ğŸ† Contributing

1. Fork the repository
2. Create a new branch (`git checkout -b feature-branch`)
3. Commit your changes (`git commit -m 'Add new feature'`)
4. Push to the branch (`git push origin feature-branch`)
5. Open a Pull Request

---

## ğŸ“œ License
This project is licensed under the MIT License.

---

## ğŸ¯ Future Improvements
- Add authentication for API access
- Deploy using Docker
- Improve UI with advanced visualizations
- Implement additional AI providers

---

## â­ Acknowledgments
Thanks to the creators of FastAPI, Streamlit, and LangChain for their amazing tools!

ğŸš€ **Feel free to star this repo and contribute!** ğŸ¯

